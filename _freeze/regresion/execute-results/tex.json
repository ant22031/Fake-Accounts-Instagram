{
  "hash": "ab33ae3c17a4526135de8dcbbda09662",
  "result": {
    "engine": "knitr",
    "markdown": "# Regresión\n\nLa regresión es una técnica estadística y de machine learning utilizada para modelar y analizar relaciones entre variables. Su objetivo principal es entender cómo cambia una variable dependiente en función de una o más variables independientes. La regresión puede ser utilizada tanto para predecir valores futuros como para entender relaciones subyacentes en los datos.\n\nEn el contexto de la detección de cuentas falsas de Instagram, la regresión es una herramienta muy útil. Entrenamos y evaluamos el modelo con conjuntos de datos de entrenamiento y prueba, utilizando métricas para asegurar su efectividad. Gracias a que tenemos dos DataSets, *train* y *test,* podemos probar nuestro modelo con datos nuevos. Finalmente, interpretamos los resultados para identificar las variables más influyentes y ajustamos el modelo para mejorar su precisión, intentando crear una herramienta fiable de detección de cuentas falsas.\n\nAhora vamos a comenzar con\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readr) \nlibrary(dplyr)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'dplyr'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(ggplot2)\ndatos <- read_csv(\"Data/train.csv\") \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 576 Columns: 12\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\ndbl (12): profile pic, nums/length username, fullname words, nums/length ful...\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\ndatosTest <- read_csv(\"Data/test.csv\") \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 120 Columns: 12\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\ndbl (12): profile pic, nums/length username, fullname words, nums/length ful...\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n\n\n\\\nAntes de intentar modelo de regresión, se debe explorar cuales son las correlaciones entre las variables numéricas.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor(datos[c(\"nums/length username\",\"fullname words\",\"description length\",\"#posts\",\"#followers\",\"#follows\")])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                     nums/length username fullname words description length\nnums/length username           1.00000000    -0.22547213       -0.321170271\nfullname words                -0.22547213     1.00000000        0.272522165\ndescription length            -0.32117027     0.27252216        1.000000000\n#posts                        -0.15744211     0.07335018        0.144823702\n#followers                    -0.06278509     0.03322460        0.005929455\n#follows                      -0.17241327     0.09485496        0.226561422\n                          #posts   #followers    #follows\nnums/length username -0.15744211 -0.062785090 -0.17241327\nfullname words        0.07335018  0.033224604  0.09485496\ndescription length    0.14482370  0.005929455  0.22656142\n#posts                1.00000000  0.321385480  0.09822504\n#followers            0.32138548  1.000000000 -0.01106599\n#follows              0.09822504 -0.011065994  1.00000000\n```\n\n\n:::\n:::\n\n\n\nVamos a ordenar las correlaciones de mayor a menor y destacar las más significativas:\n\n1.  **description length y nums/length username**: -0.32117027\n\n2.  **#followers y #posts**: 0.32138548\n\n3.  **description length y fullname words**: 0.272522165\n\n4.  **description length y #follows**: 0.226561422\n\n5.  **nums/length username y fullname words**: -0.22547213\n\n6.  **nums/length username y #follows**: -0.17241327\n\n7.  **fullname words y description length**: 0.272522165\n\n8.  **fullname words y nums/length username**: -0.22547213\n\nEstos valores nos indican las variables que tienen más relación entre sí. Es decir, las correlaciones altas señalan que cuando una variable cambia, la otra tiende a cambiar en la misma dirección o en dirección opuesta.\n\nVamos a emplear la librería `psych` para visualizar estas correlaciones de manera más intuitiva.\n\nLa parte superior de la visualización corresponde a la matriz de correlación. La diagonal muestra histogramas y además añade óvalos indicando la fuerza de correlación. Cuanto más se estire la elipse, más fuerte será la correlación. Cuanto más redondo el óvalo, más débil la correlación.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(psych)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'psych' was built under R version 4.3.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'psych'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:ggplot2':\n\n    %+%, alpha\n```\n\n\n:::\n\n```{.r .cell-code}\npairs.panels(datos[c(\"nums/length username\",\"fullname words\",\"description length\",\"#posts\",\"#followers\",\"#follows\")])\n```\n\n::: {.cell-output-display}\n![](regresion_files/figure-pdf/unnamed-chunk-3-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\nCiertamente podemos ver que donde hay mayor elipse es en *description length* y *nums/length username* y en *followers y #posts*. Por lo tanto, las tendremos mas presentes para nuestro futuro modelo de regresión.\n\n## Construcción del modelo\n\nVamos a construir un primer modelo, donde vamos a enfrentar el atributo fake a todas las demás variables. Aunque seguramente no sea el mejor modelo, nos dará una primera idea de cómo podemos ir mejorándolo.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo1 <- lm(fake ~., data = datos)\nsummary(modelo1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = fake ~ ., data = datos)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.73096 -0.23729 -0.06653  0.24048  1.01052 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(>|t|)    \n(Intercept)             7.931e-01  3.798e-02  20.880  < 2e-16 ***\n`profile pic`          -4.380e-01  3.345e-02 -13.094  < 2e-16 ***\n`nums/length username`  8.062e-01  7.522e-02  10.718  < 2e-16 ***\n`fullname words`       -3.354e-02  1.333e-02  -2.516 0.012142 *  \n`nums/length fullname` -2.775e-02  1.212e-01  -0.229 0.818988    \n`name==username`        2.241e-01  7.641e-02   2.933 0.003498 ** \n`description length`   -1.510e-03  4.342e-04  -3.478 0.000544 ***\n`external URL`         -1.542e-01  4.800e-02  -3.213 0.001390 ** \nprivate                -9.459e-03  2.843e-02  -0.333 0.739459    \n`#posts`               -9.094e-05  3.570e-05  -2.547 0.011120 *  \n`#followers`           -9.960e-09  1.539e-08  -0.647 0.517743    \n`#follows`             -1.850e-05  1.499e-05  -1.235 0.217530    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3166 on 564 degrees of freedom\nMultiple R-squared:  0.6074,\tAdjusted R-squared:  0.5998 \nF-statistic: 79.33 on 11 and 564 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\nVemos que obtenemos un modelo que no tiene un mal valor de R-squared, pero sigue siendo bajo. Además, ya podemos visualizar variables que se podrían eliminar. Esto se deduce de ver que su p-value es alto, como por ejemplo en el atributo private. Además de tener un residuo alto.\n\nVamos a ver gráficas sobre el modelo, donde podemos ver los residuos intuitivamente:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(modelo1)\n```\n\n::: {.cell-output-display}\n![](regresion_files/figure-pdf/unnamed-chunk-5-1.pdf){fig-pos='H'}\n:::\n\n::: {.cell-output-display}\n![](regresion_files/figure-pdf/unnamed-chunk-5-2.pdf){fig-pos='H'}\n:::\n\n::: {.cell-output-display}\n![](regresion_files/figure-pdf/unnamed-chunk-5-3.pdf){fig-pos='H'}\n:::\n\n::: {.cell-output-display}\n![](regresion_files/figure-pdf/unnamed-chunk-5-4.pdf){fig-pos='H'}\n:::\n:::\n\n\n\nPodemos utilizar la gráfica de Residuals vs Leverage para ver la influencia de los puntos en nuestro modelo. Con esta información, observamos que en general no hay muchos puntos que afecten al modelo, los llamados \"outliers\"; solo podemos distinguir el 45, 25 y 41, los cuales pueden ser eliminados para mejorar el modelo.\n\nPodemos visualizar la distribución de los residuos para evaluar si estos se comportan de manera aproximadamente normal, un supuesto común en muchos modelos estadísticos.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n plot(density(resid(modelo1)))\n```\n\n::: {.cell-output-display}\n![](regresion_files/figure-pdf/unnamed-chunk-6-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\nLa forma de la gráfica sugiere que los residuos del modelo no se distribuyen de forma normal y que podría haber problemas con el modelo.\n\nPor último, vamos a ver el modelo prediciendo gráficamente. Podemos utilizar los datos de prueba que nos proporciona nuestro dataset.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo1_predic <- predict(modelo1, newdata = datosTest)\n\ndatosTest1 <- datosTest %>% mutate(pred = modelo1_predic)\n\n# Rojos -> Reales, verdes -> Predichos\nggplot(datosTest1, aes(x = pred, y = fake)) +\n  geom_point(color = \"red\") +              \n  geom_point(aes(x = pred, y = pred),      \n             color = \"green\", shape = 1) +\n  labs(title = \"Comparación de valores reales y predichos\",\n       x = \"Valores Predichos\",\n       y = \"Valores Reales\") +\n  theme_minimal()                        \n```\n\n::: {.cell-output-display}\n![](regresion_files/figure-pdf/unnamed-chunk-7-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\nVemos que ciertamente, al usar una regresión \"lineal\", los valores se disponen en una linea recta, la que corresponde a la ecuación obtenida gracias a `lm.`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoef(modelo1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           (Intercept)          `profile pic` `nums/length username` \n          7.930850e-01          -4.380333e-01           8.062047e-01 \n      `fullname words` `nums/length fullname`       `name==username` \n         -3.354355e-02          -2.775272e-02           2.240837e-01 \n  `description length`         `external URL`                private \n         -1.510047e-03          -1.542026e-01          -9.459373e-03 \n              `#posts`           `#followers`             `#follows` \n         -9.094368e-05          -9.960487e-09          -1.850049e-05 \n```\n\n\n:::\n:::\n\n\n\nUna vez visto que nuestro modelo inicial, con todas las variables, no es del todo bueno, vamos a eliminar variables con p-values altos, outliers, ... e intentar mejorarlo.\n\n## Mejorando el modelo\n\n### Eliminando Outliers\n\nVamos a eliminar los valores que están muy separados y que pueden afectar al modelo.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndatos <- datos[-c(45,25,41),]\ndatos <- datos[-c(440,412,396),]\ndatos <- datos[-c(351,364,174),]\ndatos <- datos[-c(140,446,449),]\n```\n:::\n\n\n\nHay que hacerlo con moderación ya que si eliminamos muchos valores que realmente no son \"outliers\" estamos obteniendo mejores modelos pero que realmente no son así.\n\n## Eliminar variables no significativas\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo2 <- lm(fake ~\n                `profile pic`+\n                `nums/length username`+\n                `fullname words`+\n                `name==username`+\n                `description length`+\n                `external URL`+\n                `#posts`    , data = datos)\nsummary(modelo2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = fake ~ `profile pic` + `nums/length username` + \n    `fullname words` + `name==username` + `description length` + \n    `external URL` + `#posts`, data = datos)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.74205 -0.22951 -0.06475  0.22687  0.83615 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(>|t|)    \n(Intercept)             8.144e-01  3.594e-02  22.656  < 2e-16 ***\n`profile pic`          -4.297e-01  3.140e-02 -13.685  < 2e-16 ***\n`nums/length username`  7.921e-01  6.561e-02  12.072  < 2e-16 ***\n`fullname words`       -5.062e-02  1.573e-02  -3.218  0.00136 ** \n`name==username`        1.471e-01  7.287e-02   2.019  0.04397 *  \n`description length`   -2.251e-03  4.363e-04  -5.160 3.45e-07 ***\n`external URL`         -5.622e-02  4.740e-02  -1.186  0.23609    \n`#posts`               -3.114e-04  7.568e-05  -4.115 4.46e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3003 on 556 degrees of freedom\nMultiple R-squared:  0.6443,\tAdjusted R-squared:  0.6399 \nF-statistic: 143.9 on 7 and 556 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\nHemos obtenido un modelo un poco mejor y con menos residuos, ahora vamos a intentar mejorar este modelo usando variables no lineales.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo3 <- lm(fake ~ \n                `profile pic` +\n                `nums/length username` +\n                `fullname words` +\n                `name==username` +\n                `description length` +\n                `external URL` +\n                `#posts` +\n                I(`nums/length username`^2)+\n                I(`description length`^2)+\n                I(`#posts`^2),\n              data = datos)\n\nsummary(modelo3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = fake ~ `profile pic` + `nums/length username` + \n    `fullname words` + `name==username` + `description length` + \n    `external URL` + `#posts` + I(`nums/length username`^2) + \n    I(`description length`^2) + I(`#posts`^2), data = datos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.7340 -0.1915 -0.0474  0.2155  0.8442 \n\nCoefficients:\n                              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                  7.954e-01  3.627e-02  21.933  < 2e-16 ***\n`profile pic`               -3.725e-01  3.123e-02 -11.925  < 2e-16 ***\n`nums/length username`       1.281e+00  1.547e-01   8.283 9.11e-16 ***\n`fullname words`            -4.750e-02  1.510e-02  -3.145  0.00175 ** \n`name==username`             1.168e-01  7.019e-02   1.664  0.09663 .  \n`description length`        -6.116e-03  1.099e-03  -5.568 4.03e-08 ***\n`external URL`              -3.135e-02  4.616e-02  -0.679  0.49739    \n`#posts`                    -8.571e-04  1.760e-04  -4.871 1.45e-06 ***\nI(`nums/length username`^2) -8.867e-01  2.235e-01  -3.967 8.23e-05 ***\nI(`description length`^2)    3.476e-05  8.677e-06   4.006 7.03e-05 ***\nI(`#posts`^2)                6.033e-07  1.666e-07   3.621  0.00032 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.288 on 553 degrees of freedom\nMultiple R-squared:  0.6747,\tAdjusted R-squared:  0.6688 \nF-statistic: 114.7 on 10 and 553 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\nVemos, que nuestro modelo ha mejorado un poco y tenemos menos residuos, que es lo que estamos buscando.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(modelo3)\n```\n\n::: {.cell-output-display}\n![](regresion_files/figure-pdf/unnamed-chunk-12-1.pdf){fig-pos='H'}\n:::\n\n::: {.cell-output-display}\n![](regresion_files/figure-pdf/unnamed-chunk-12-2.pdf){fig-pos='H'}\n:::\n\n::: {.cell-output-display}\n![](regresion_files/figure-pdf/unnamed-chunk-12-3.pdf){fig-pos='H'}\n:::\n\n::: {.cell-output-display}\n![](regresion_files/figure-pdf/unnamed-chunk-12-4.pdf){fig-pos='H'}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n plot(density(resid(modelo3)))\n```\n\n::: {.cell-output-display}\n![](regresion_files/figure-pdf/unnamed-chunk-13-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\nSeguimos teniendo una distribución de residuos asimétrica y no normal.\n\nVamos a visualizar como predice este nuevo modelo:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo3_predic <- predict(modelo3, newdata = datosTest)\n\ndatosTest3 <- datosTest %>% mutate(pred = modelo3_predic)\n\n# Rojos -> Reales, verdes -> Predichos\nggplot(datosTest3, aes(x = pred, y = fake)) +\n  geom_point(color = \"red\") +              \n  geom_point(aes(x = pred, y = pred),      \n             color = \"green\", shape = 1) +\n  labs(title = \"Comparación de valores reales y predichos\",\n       x = \"Valores Predichos\",\n       y = \"Valores Reales\") +\n  theme_minimal()           \n```\n\n::: {.cell-output-display}\n![](regresion_files/figure-pdf/unnamed-chunk-14-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\nSin embargo, este gráfico, al ser los valores entre 0 y 1 es un poco confuso, vamos a ver el porcentaje de acierto mejor:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndatosTest3 <- datosTest3 %>% mutate(pred = ifelse(modelo3_predic < 0.5, 0, 1))\n# Calcular el porcentaje de aciertos\naccuracy <- mean(datosTest3$pred == datosTest3$fake) * 100\naccuracy\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 87.5\n```\n\n\n:::\n:::\n\n\n\nVemos que ha acertado un 87.5% de las veces, un dato bastante bueno.\n\n### Exportar el modelo\n\nPara poder utilizar el modelo en futuras aplicaciones, podemos guardarlo de la forma:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsave(modelo3, file = \"modelo3.rds\")\n```\n:::\n\n\n\n## Interacciones entre variables\n\nAl incluir términos de interacción en el modelo de regresión, permitimos que el efecto de una variable sobre la otra varíe según los niveles de otras variables incluidas en la interacción.\n\nEsto puede ser importante para capturar relaciones más complejas entre las variables.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo_interact <- lm(fake ~ `profile pic` * `nums/length username` +\n                                       `fullname words` * `description length` +\n                                       `name==username` * `external URL` +\n                                       `#posts`, data = datos)\nsummary(modelo_interact)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = fake ~ `profile pic` * `nums/length username` + \n    `fullname words` * `description length` + `name==username` * \n    `external URL` + `#posts`, data = datos)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.96028 -0.15321  0.00288  0.06898  0.93053 \n\nCoefficients:\n                                        Estimate Std. Error t value Pr(>|t|)\n(Intercept)                            1.032e+00  4.025e-02  25.644  < 2e-16\n`profile pic`                         -7.191e-01  4.077e-02 -17.637  < 2e-16\n`nums/length username`                 4.660e-02  9.326e-02   0.500 0.617496\n`fullname words`                      -5.708e-02  1.795e-02  -3.180 0.001555\n`description length`                  -2.705e-03  7.093e-04  -3.814 0.000152\n`name==username`                       1.487e-01  6.866e-02   2.166 0.030756\n`external URL`                        -3.287e-02  4.372e-02  -0.752 0.452397\n`#posts`                              -2.603e-04  6.964e-05  -3.738 0.000204\n`profile pic`:`nums/length username`   1.250e+00  1.214e-01  10.297  < 2e-16\n`fullname words`:`description length`  4.841e-04  3.308e-04   1.463 0.143985\n`name==username`:`external URL`       -1.903e-01  2.866e-01  -0.664 0.507019\n                                         \n(Intercept)                           ***\n`profile pic`                         ***\n`nums/length username`                   \n`fullname words`                      ** \n`description length`                  ***\n`name==username`                      *  \n`external URL`                           \n`#posts`                              ***\n`profile pic`:`nums/length username`  ***\n`fullname words`:`description length`    \n`name==username`:`external URL`          \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2749 on 553 degrees of freedom\nMultiple R-squared:  0.7037,\tAdjusted R-squared:  0.6984 \nF-statistic: 131.3 on 10 and 553 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n\n```{.r .cell-code}\n# Guardar el modelo en un archivo\nsaveRDS(modelo_interact, file = \"modelo_interact.rds\")\n```\n:::\n\n\n\nEste modelo vemos que ha mejorado frente a todos loa anteriores, por lo que tenemos que tenerlo en cuenta para nuestro modelo final.\n\n## Ingeniería de variables\n\nLa ingeniería de variables implica crear nuevas variables o transformar las existentes para mejorar el rendimiento de un modelo predictivo. Esto incluye crear características nuevas, transformar las existentes, entre otras técnicas.\n\nVamos a probarlo en nuestro modelo.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo_nuevasVar <- lm(fake ~ `profile pic`+\n                                    `nums/length username` +\n                                    log(`description length` + 1) +\n                                    `name==username` +\n                                    log(`#posts`+1), data = datos)\nsummary(modelo_nuevasVar)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = fake ~ `profile pic` + `nums/length username` + \n    log(`description length` + 1) + `name==username` + log(`#posts` + \n    1), data = datos)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.66063 -0.18128 -0.01962  0.16008  0.96220 \n\nCoefficients:\n                               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                    0.839917   0.028606  29.362  < 2e-16 ***\n`profile pic`                 -0.248421   0.033391  -7.440 3.83e-13 ***\n`nums/length username`         0.659306   0.061590  10.705  < 2e-16 ***\nlog(`description length` + 1) -0.050486   0.007843  -6.437 2.62e-10 ***\n`name==username`               0.107825   0.066988   1.610    0.108    \nlog(`#posts` + 1)             -0.080978   0.007900 -10.251  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2757 on 558 degrees of freedom\nMultiple R-squared:  0.6992,\tAdjusted R-squared:  0.6965 \nF-statistic: 259.4 on 5 and 558 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n\n```{.r .cell-code}\n# Guardar el modelo en un archivo\nsaveRDS(modelo_nuevasVar, file = \"modelo_nuevasVar.rds\")\n```\n:::\n\n\n\nDe nuevo, este modelo ha sido mejor que todos los anteriores simplemente añadiendo el logaritmo de unas variables.\n\n## Modelo final\n\nVamos a combinar todos los métodos anteriores para encontrar el mejor modelo posible. Aplicaremos tanto variables no lineales como ingeniería de variables e interacción entre variables.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo_final <- lm(fake ~ `profile pic` * `nums/length username` +\n                                log(`description length` + 1) +\n                                `name==username` +\n                                log(`#posts`+1)+\n                                `#followers` +\n                                I(`nums/length username`^2)+\n                                I(`description length`^2)+\n                                I(`#posts`^2),\n                         data = datos)\n\nsummary(modelo_final)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = fake ~ `profile pic` * `nums/length username` + \n    log(`description length` + 1) + `name==username` + log(`#posts` + \n    1) + `#followers` + I(`nums/length username`^2) + I(`description length`^2) + \n    I(`#posts`^2), data = datos)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.70351 -0.11215 -0.00771  0.08622  1.01284 \n\nCoefficients:\n                                       Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                           9.732e-01  3.395e-02  28.666  < 2e-16 ***\n`profile pic`                        -5.097e-01  4.432e-02 -11.500  < 2e-16 ***\n`nums/length username`                4.255e-01  1.583e-01   2.687  0.00742 ** \nlog(`description length` + 1)        -4.738e-02  9.109e-03  -5.201 2.79e-07 ***\n`name==username`                      9.404e-02  6.232e-02   1.509  0.13188    \nlog(`#posts` + 1)                    -6.765e-02  8.414e-03  -8.041 5.44e-15 ***\n`#followers`                          1.126e-09  2.733e-08   0.041  0.96716    \nI(`nums/length username`^2)          -5.574e-01  2.000e-01  -2.788  0.00549 ** \nI(`description length`^2)             2.373e-06  3.410e-06   0.696  0.48676    \nI(`#posts`^2)                         8.394e-08  6.657e-08   1.261  0.20789    \n`profile pic`:`nums/length username`  1.024e+00  1.158e-01   8.847  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2557 on 553 degrees of freedom\nMultiple R-squared:  0.7435,\tAdjusted R-squared:  0.7389 \nF-statistic: 160.3 on 10 and 553 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\nVemos que el mejor modelo que hemos conseguido obtener ha mejorado bastante respecto al primer modelo obtenido, teniendo un mejor R cuadrado y menos residuos. Vamos a ver las demás métricas utilizadas anteriormente.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(modelo_final)\n```\n\n::: {.cell-output-display}\n![](regresion_files/figure-pdf/unnamed-chunk-20-1.pdf){fig-pos='H'}\n:::\n\n::: {.cell-output-display}\n![](regresion_files/figure-pdf/unnamed-chunk-20-2.pdf){fig-pos='H'}\n:::\n\n::: {.cell-output-display}\n![](regresion_files/figure-pdf/unnamed-chunk-20-3.pdf){fig-pos='H'}\n:::\n\n::: {.cell-output-display}\n![](regresion_files/figure-pdf/unnamed-chunk-20-4.pdf){fig-pos='H'}\n:::\n:::\n\n\n\nVamos a generar predicciones con el dataSet de test.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generar predicciones\nmodeloFinal_predic <- predict(modelo_final, newdata = datosTest)\n\n\ndatosTestFinal <- datosTest %>% mutate(pred = ifelse(modeloFinal_predic < 0.5, 0, 1))\n# Calcular el porcentaje de aciertos\naccuracy <- mean(datosTestFinal$pred == datosTestFinal$fake) * 100\naccuracy\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 87.5\n```\n\n\n:::\n:::\n\n\n\nPor último, vemos que obtenemos un buen porcentaje de acierto con nuestro dataSet de prueba,\n\n## Otros modelos de regresión\n\nVamos a explorar otros modelos de regresión diferentes al clásico modelo de regeresion lineal que hemos estado trabajando hasta ahora. Puede ser que para nuestra investigación, un modelo diferente al lineal sea mas conveniente y nos pudiera ayudar mas.\n\n### Random Forest\n\nRandom Forest es un algoritmo de aprendizaje automático que se basa en la idea de crear múltiples árboles de decisión durante el proceso de entrenamiento y luego combinar sus predicciones para obtener una predicción más robusta y precisa.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(randomForest)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'randomForest' was built under R version 4.3.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nrandomForest 4.7-1.1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nType rfNews() to see new features/changes/bug fixes.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'randomForest'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:psych':\n\n    outlier\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:ggplot2':\n\n    margin\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:dplyr':\n\n    combine\n```\n\n\n:::\n\n```{.r .cell-code}\ndatosdf <- data.frame(datos)\n# Crea el modelo de Random Forest\nmodelo_rf <- randomForest(fake ~ .,ntree=4, data = datosdf)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in randomForest.default(m, y, ...): The response has five or fewer\nunique values.  Are you sure you want to do regression?\n```\n\n\n:::\n\n```{.r .cell-code}\n# Resumen del modelo\nprint(modelo_rf)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\n randomForest(formula = fake ~ ., data = datosdf, ntree = 4) \n               Type of random forest: regression\n                     Number of trees: 4\nNo. of variables tried at each split: 3\n\n          Mean of squared residuals: 0.07621379\n                    % Var explained: 69.51\n```\n\n\n:::\n:::\n\n\n\n##### Importancia de las variables\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimportance(modelo_rf)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                     IncNodePurity\nprofile.pic             23.7703260\nnums.length.username    15.2267161\nfullname.words           9.6991688\nnums.length.fullname     3.2508379\nname..username           0.6692343\ndescription.length      18.2050266\nexternal.URL             1.0490664\nprivate                  0.8469135\nX.posts                  9.8820519\nX.followers             44.7077969\nX.follows                7.4875299\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodeloRF_predic <- predict(modelo_rf, newdata = data.frame(datosTest))\n\n\nmodeloRF_predic <- datosTest %>% mutate(pred = ifelse(modeloRF_predic < 0.5, 0, 1))\n# Calcular el porcentaje de aciertos\naccuracy <- mean(modeloRF_predic$pred == modeloRF_predic$fake) * 100\naccuracy\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 92.5\n```\n\n\n:::\n:::\n\n\n\n### Generalized Additive Model\n\nUn GAM es un tipo de modelo estadístico que generaliza los modelos lineales al permitir relaciones no lineales entre las variables predictoras y la variable de respuesta.\n\nEn lugar de suponer una relación lineal entre las variables, los GAM permiten que cada variable explicativa tenga una relación suave con la variable de respuesta, modelada a través de funciones suaves.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mgcv)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'mgcv' was built under R version 4.3.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: nlme\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'nlme' was built under R version 4.3.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'nlme'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:dplyr':\n\n    collapse\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThis is mgcv 1.9-1. For overview type 'help(\"mgcv-package\")'.\n```\n\n\n:::\n\n```{.r .cell-code}\nmodelo_gam = gam(fake ~ profile.pic +\n               nums.length.username +\n               fullname.words +\n               nums.length.fullname +\n               name..username +\n               description.length +\n               external.URL +\n               private +\n               X.posts +\n               X.followers +\n               X.follows, \n             data = datosdf)\n\nsummary(modelo_gam)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nFamily: gaussian \nLink function: identity \n\nFormula:\nfake ~ profile.pic + nums.length.username + fullname.words + \n    nums.length.fullname + name..username + description.length + \n    external.URL + private + X.posts + X.followers + X.follows\n\nParametric coefficients:\n                       Estimate Std. Error t value Pr(>|t|)    \n(Intercept)           8.190e-01  3.828e-02  21.397  < 2e-16 ***\nprofile.pic          -4.272e-01  3.221e-02 -13.264  < 2e-16 ***\nnums.length.username  7.855e-01  7.193e-02  10.921  < 2e-16 ***\nfullname.words       -5.088e-02  1.587e-02  -3.205 0.001427 ** \nnums.length.fullname  1.413e-02  1.160e-01   0.122 0.903121    \nname..username        1.461e-01  7.724e-02   1.891 0.059126 .  \ndescription.length   -2.262e-03  4.422e-04  -5.115 4.33e-07 ***\nexternal.URL         -5.643e-02  4.800e-02  -1.176 0.240246    \nprivate              -8.206e-03  2.738e-02  -0.300 0.764497    \nX.posts              -3.042e-04  7.783e-05  -3.908 0.000105 ***\nX.followers          -1.982e-08  3.227e-08  -0.614 0.539287    \nX.follows            -3.659e-06  1.456e-05  -0.251 0.801712    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nR-sq.(adj) =  0.638   Deviance explained = 64.5%\nGCV = 0.092734  Scale est. = 0.090761  n = 564\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodeloGam_predic <- predict(modelo_gam, newdata = data.frame(datosTest))\n\n\nmodeloGam_predic <- datosTest %>% mutate(pred = ifelse(modeloGam_predic < 0.5, 0, 1))\n# Calcular el porcentaje de aciertos\naccuracy <- mean(modeloGam_predic$pred == modeloGam_predic$fake) * 100\naccuracy\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 89.16667\n```\n\n\n:::\n:::\n\n\n\n## Conclusiones\n\nHemos explorado tanto los tradicionales modelos lineales como también nuevos enfoques de regresión. Durante este proceso, hemos descubierto modelos interesantes que muestran un potencial considerable para generar predicciones precisas en contextos del mundo real. Al aplicar estos modelos a conjuntos de datos reales, estamos equipados para abordar problemas complejos y tenemos la herramientas para realizar predicciones certeras sobre datos reales, pudiendo servir de verdadera ayuda en el mundo real.\n",
    "supporting": [
      "regresion_files\\figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}